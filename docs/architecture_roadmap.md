# Architecture Roadmap: Prefect Pipeline Implementation

## ğŸ¯ **Priority Sequence (Sprint 2+)**

### **Phase 1: Document Processing Pipeline (Foundation)**
```
Document Upload â†’ Document Parser â†’ Structured Content
                                â†“
                        Two Parallel Pipelines:
                         â†“              â†“
                   RAG Pipeline    Extraction Pipeline
```

**Why First:** All downstream processing depends on clean, parsed document content.

**ğŸš€ Docling Advantage:** Using Docling for unified document processing provides:
- **Single API** for PDF, DOCX, and Image processing
- **Consistent output format** across all document types
- **Built-in structure detection** (tables, headings, sections)
- **Simplified architecture** - no need for multiple parsers
- **Better maintainability** - one processing pipeline to maintain

**Core Components to Build:**
1. **DoclingProcessor** - Unified document processing for PDF/DOCX/Images using Docling
2. **DocumentStructureAnalyzer** - Extract and analyze document structure from Docling output
3. **ContentExtractor** - Clean text and metadata extraction from Docling results
4. **ContentValidator** - Ensure parsing quality and completeness

---

### **Phase 2: RAG Processing Pipeline**
```
Parsed Content â†’ Semantic Chunker â†’ Embeddings â†’ Vector Storage â†’ RAG Ready
```

**Core Components:**
1. **SemanticChunker** - Intelligent text splitting
2. **EmbeddingService** - Generate vector embeddings  
3. **ChromaRepository** - Vector storage operations
4. **ChunkValidator** - Quality assurance

---

### **Phase 3: Structured Extraction Pipeline**
```
Parsed Content â†’ Field Discovery â†’ Agent Swarm â†’ Data Extraction â†’ Structured Storage
```

**Core Components:**
1. **FieldDiscoveryAgent** - Auto-detect extractable fields
2. **AgentScalingManager** - Dynamic agent allocation
3. **ExtractionAgent** - Structured data extraction
4. **DataValidator** - Extracted data quality

---

## ğŸ—ï¸ **Pipeline Architecture**

### **Phase 1: Document Processing Components**
```python
src/backend/doc_processing_system/pipelines/
â”œâ”€â”€ document_processing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ docling_processor.py          # Unified Docling-based document processing
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ structure_analyzer.py     # Extract structure from Docling output
â”‚   â”‚   â”œâ”€â”€ content_extractor.py      # Clean text/metadata extraction
â”‚   â”‚   â””â”€â”€ content_validator.py      # Quality assurance
â”‚   â””â”€â”€ flows/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ document_processing_flow.py  # Main Prefect flow
```

### **Phase 2: RAG Pipeline Components**
```python
â”œâ”€â”€ rag_processing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ semantic_chunker.py           # Intelligent chunking
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embedding_service.py      # Vector generation
â”‚   â”‚   â”œâ”€â”€ chroma_repository.py      # Vector storage
â”‚   â”‚   â””â”€â”€ chunk_validator.py        # Quality control
â”‚   â””â”€â”€ flows/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ rag_processing_flow.py    # RAG Prefect flow
```

### **Phase 3: Extraction Pipeline Components**
```python
â”œâ”€â”€ structured_extraction/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ field_discovery_agent.py      # Auto field detection
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent_scaling_manager.py  # Dynamic scaling
â”‚   â”‚   â”œâ”€â”€ extraction_agent.py       # Data extraction
â”‚   â”‚   â””â”€â”€ data_validator.py         # Result validation
â”‚   â””â”€â”€ flows/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ extraction_flow.py        # Extraction Prefect flow
```

### **Orchestration Layer**
```python
â””â”€â”€ orchestration/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ main_flow.py                  # Master orchestrator
    â”œâ”€â”€ flow_coordinator.py           # Inter-pipeline coordination
    â””â”€â”€ deployment/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ flow_deployments.py       # Prefect deployment configs
```

---

## ğŸš€ **Prefect Flow Architecture**

### **Main Orchestrator Flow:**
```python
@flow(name="document-processing-master")
def process_document(document_id: str, file_path: str):
    # Phase 1: Document Processing
    parsed_content = document_processing_flow(document_id, file_path)
    
    # Phase 2 & 3: Parallel Processing
    rag_future = rag_processing_flow.submit(document_id, parsed_content)
    extraction_future = extraction_flow.submit(document_id, parsed_content)
    
    # Wait for completion
    rag_result = rag_future.result()
    extraction_result = extraction_future.result()
    
    return {
        "document_id": document_id,
        "rag_result": rag_result,
        "extraction_result": extraction_result
    }
```

### **Individual Pipeline Flows:**
```python
@flow(name="document-processing")
def document_processing_flow(document_id: str, file_path: str):
    # Tasks for parsing, extraction, validation
    pass

@flow(name="rag-processing") 
def rag_processing_flow(document_id: str, content: str):
    # Tasks for chunking, embedding, storage
    pass

@flow(name="structured-extraction")
def extraction_flow(document_id: str, content: str):
    # Tasks for field discovery, agent processing
    pass
```

---

## ğŸ“Š **Success Metrics Per Phase**

### **Phase 1 Complete When:**
- âœ… Upload PDF â†’ Get clean parsed text + structure via Docling
- âœ… Upload DOCX â†’ Get clean parsed text + structure via Docling  
- âœ… Upload Image â†’ Get OCR text + structure via Docling
- âœ… Unified document processing Prefect flow working
- âœ… All document types processed through single Docling pipeline

### **Phase 2 Complete When:**
- âœ… Parsed content â†’ Semantic chunks created
- âœ… Chunks â†’ Vector embeddings generated
- âœ… Embeddings â†’ Stored in ChromaDB
- âœ… RAG processing Prefect flow working

### **Phase 3 Complete When:**
- âœ… Document â†’ Auto-discovered extractable fields
- âœ… Fields â†’ Agent swarm processes document
- âœ… Extraction â†’ Structured data in database
- âœ… Extraction Prefect flow working

---

## ğŸ¯ **Implementation Strategy**

1. **Build Pipeline Structure** â†’ Create pipelines/ directory with proper organization
2. **Implement Phase 1** â†’ Document processing components and Prefect flow
3. **Implement Phase 2** â†’ RAG pipeline components and Prefect flow
4. **Implement Phase 3** â†’ Extraction pipeline components and Prefect flow
5. **Orchestrate** â†’ Master flow to coordinate all pipelines
6. **Deploy** â†’ Prefect deployment configurations

**Focus:** Build robust, testable pipeline components with clear separation of concerns and comprehensive Prefect flow orchestration.